module attributes {torch.debug_module_name = "ResNet"} {
    func.func @forward(%arg0: !torch.vtensor<[1,3,224,224],f32>) -> !torch.vtensor<[1,1000],f32> {
      %int7 = torch.constant.int 7
      %true = torch.constant.bool true
      %false = torch.constant.bool false
      %0 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<1000xf32>) : !torch.vtensor<[1000],f32>
      %1 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<1000x512xf32>) : !torch.vtensor<[1000,512],f32>
      %2 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %3 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %4 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %5 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %6 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512x512x3x3xf32>) : !torch.vtensor<[512,512,3,3],f32>
      %7 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %8 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %9 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %10 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %11 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512x512x3x3xf32>) : !torch.vtensor<[512,512,3,3],f32>
      %12 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %13 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %14 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %15 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512x256x1x1xf32>) : !torch.vtensor<[512,256,1,1],f32>
      %16 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %17 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %18 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %19 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %20 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512x512x3x3xf32>) : !torch.vtensor<[512,512,3,3],f32>
      %21 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %22 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %23 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %24 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512xf32>) : !torch.vtensor<[512],f32>
      %25 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<512x256x3x3xf32>) : !torch.vtensor<[512,256,3,3],f32>
      %26 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %27 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %28 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %29 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %30 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256x256x3x3xf32>) : !torch.vtensor<[256,256,3,3],f32>
      %31 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %32 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %33 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %34 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %35 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256x256x3x3xf32>) : !torch.vtensor<[256,256,3,3],f32>
      %36 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %37 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %38 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %39 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256x128x1x1xf32>) : !torch.vtensor<[256,128,1,1],f32>
      %40 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %41 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %42 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %43 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %44 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256x256x3x3xf32>) : !torch.vtensor<[256,256,3,3],f32>
      %45 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %46 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %47 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %48 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256xf32>) : !torch.vtensor<[256],f32>
      %49 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<256x128x3x3xf32>) : !torch.vtensor<[256,128,3,3],f32>
      %50 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %51 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %52 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %53 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %54 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128x128x3x3xf32>) : !torch.vtensor<[128,128,3,3],f32>
      %55 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %56 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %57 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %58 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %59 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128x128x3x3xf32>) : !torch.vtensor<[128,128,3,3],f32>
      %60 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %61 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %62 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %63 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128x64x1x1xf32>) : !torch.vtensor<[128,64,1,1],f32>
      %64 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %65 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %66 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %67 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %68 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128x128x3x3xf32>) : !torch.vtensor<[128,128,3,3],f32>
      %69 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %70 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %71 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %72 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128xf32>) : !torch.vtensor<[128],f32>
      %73 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<128x64x3x3xf32>) : !torch.vtensor<[128,64,3,3],f32>
      %74 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %75 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %76 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %77 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %78 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64x64x3x3xf32>) : !torch.vtensor<[64,64,3,3],f32>
      %79 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %80 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %81 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %82 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %83 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64x64x3x3xf32>) : !torch.vtensor<[64,64,3,3],f32>
      %84 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %85 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %86 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %87 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %88 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64x64x3x3xf32>) : !torch.vtensor<[64,64,3,3],f32>
      %89 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %90 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %91 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %92 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %93 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64x64x3x3xf32>) : !torch.vtensor<[64,64,3,3],f32>
      %94 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %95 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %96 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %97 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64xf32>) : !torch.vtensor<[64],f32>
      %98 = torch.vtensor.literal(opaque<"elided_large_const", "0xDEADBEEF"> : tensor<64x3x7x7xf32>) : !torch.vtensor<[64,3,7,7],f32>
      %int3 = torch.constant.int 3
      %int2 = torch.constant.int 2
      %int1 = torch.constant.int 1
      %int-1 = torch.constant.int -1
      %int0 = torch.constant.int 0
      %float1.000000e-05 = torch.constant.float 1.000000e-05
      %float1.000000e-01 = torch.constant.float 1.000000e-01
      %none = torch.constant.none
      %99 = torch.prim.ListConstruct %int2, %int2 : (!torch.int, !torch.int) -> !torch.list<int>
      %100 = torch.prim.ListConstruct %int3, %int3 : (!torch.int, !torch.int) -> !torch.list<int>
      %101 = torch.prim.ListConstruct %int1, %int1 : (!torch.int, !torch.int) -> !torch.list<int>
      %102 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %103 = torch.aten.convolution %arg0, %98, %none, %99, %100, %101, %false, %102, %int1 : !torch.vtensor<[1,3,224,224],f32>, !torch.vtensor<[64,3,7,7],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,64,112,112],f32>
      %104 = torch.aten.batch_norm %103, %95, %94, %97, %96, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,64,112,112],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,64,112,112],f32>
      %105 = torch.aten.relu %104 : !torch.vtensor<[1,64,112,112],f32> -> !torch.vtensor<[1,64,112,112],f32>
      %106 = torch.aten.max_pool2d %105, %100, %99, %101, %101, %false : !torch.vtensor<[1,64,112,112],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool -> !torch.vtensor<[1,64,56,56],f32>
      %107 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %108 = torch.aten.convolution %106, %93, %none, %101, %101, %101, %false, %107, %int1 : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[64,64,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,64,56,56],f32>
      %109 = torch.aten.batch_norm %108, %90, %89, %92, %91, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,64,56,56],f32>
      %110 = torch.aten.relu %109 : !torch.vtensor<[1,64,56,56],f32> -> !torch.vtensor<[1,64,56,56],f32>
      %111 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %112 = torch.aten.convolution %110, %88, %none, %101, %101, %101, %false, %111, %int1 : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[64,64,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,64,56,56],f32>
      %113 = torch.aten.batch_norm %112, %85, %84, %87, %86, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,64,56,56],f32>
      %114 = torch.aten.add.Tensor %113, %106, %int1 : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[1,64,56,56],f32>, !torch.int -> !torch.vtensor<[1,64,56,56],f32>
      %115 = torch.aten.relu %114 : !torch.vtensor<[1,64,56,56],f32> -> !torch.vtensor<[1,64,56,56],f32>
      %116 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %117 = torch.aten.convolution %115, %83, %none, %101, %101, %101, %false, %116, %int1 : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[64,64,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,64,56,56],f32>
      %118 = torch.aten.batch_norm %117, %80, %79, %82, %81, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,64,56,56],f32>
      %119 = torch.aten.relu %118 : !torch.vtensor<[1,64,56,56],f32> -> !torch.vtensor<[1,64,56,56],f32>
      %120 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %121 = torch.aten.convolution %119, %78, %none, %101, %101, %101, %false, %120, %int1 : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[64,64,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,64,56,56],f32>
      %122 = torch.aten.batch_norm %121, %75, %74, %77, %76, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.vtensor<[64],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,64,56,56],f32>
      %123 = torch.aten.add.Tensor %122, %115, %int1 : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[1,64,56,56],f32>, !torch.int -> !torch.vtensor<[1,64,56,56],f32>
      %124 = torch.aten.relu %123 : !torch.vtensor<[1,64,56,56],f32> -> !torch.vtensor<[1,64,56,56],f32>
      %125 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %126 = torch.aten.convolution %124, %73, %none, %99, %101, %101, %false, %125, %int1 : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[128,64,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,28,28],f32>
      %127 = torch.aten.batch_norm %126, %70, %69, %72, %71, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,128,28,28],f32>
      %128 = torch.aten.relu %127 : !torch.vtensor<[1,128,28,28],f32> -> !torch.vtensor<[1,128,28,28],f32>
      %129 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %130 = torch.aten.convolution %128, %68, %none, %101, %101, %101, %false, %129, %int1 : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[128,128,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,28,28],f32>
      %131 = torch.aten.batch_norm %130, %65, %64, %67, %66, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,128,28,28],f32>
      %132 = torch.prim.ListConstruct %int0, %int0 : (!torch.int, !torch.int) -> !torch.list<int>
      %133 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %134 = torch.aten.convolution %124, %63, %none, %99, %132, %101, %false, %133, %int1 : !torch.vtensor<[1,64,56,56],f32>, !torch.vtensor<[128,64,1,1],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,28,28],f32>
      %135 = torch.aten.batch_norm %134, %60, %64, %62, %61, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,128,28,28],f32>
      %136 = torch.aten.add.Tensor %131, %135, %int1 : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[1,128,28,28],f32>, !torch.int -> !torch.vtensor<[1,128,28,28],f32>
      %137 = torch.aten.relu %136 : !torch.vtensor<[1,128,28,28],f32> -> !torch.vtensor<[1,128,28,28],f32>
      %138 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %139 = torch.aten.convolution %137, %59, %none, %101, %101, %101, %false, %138, %int1 : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[128,128,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,28,28],f32>
      %140 = torch.aten.batch_norm %139, %56, %55, %58, %57, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,128,28,28],f32>
      %141 = torch.aten.relu %140 : !torch.vtensor<[1,128,28,28],f32> -> !torch.vtensor<[1,128,28,28],f32>
      %142 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %143 = torch.aten.convolution %141, %54, %none, %101, %101, %101, %false, %142, %int1 : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[128,128,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,128,28,28],f32>
      %144 = torch.aten.batch_norm %143, %51, %50, %53, %52, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.vtensor<[128],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,128,28,28],f32>
      %145 = torch.aten.add.Tensor %144, %137, %int1 : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[1,128,28,28],f32>, !torch.int -> !torch.vtensor<[1,128,28,28],f32>
      %146 = torch.aten.relu %145 : !torch.vtensor<[1,128,28,28],f32> -> !torch.vtensor<[1,128,28,28],f32>
      %147 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %148 = torch.aten.convolution %146, %49, %none, %99, %101, %101, %false, %147, %int1 : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[256,128,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,14,14],f32>
      %149 = torch.aten.batch_norm %148, %46, %45, %48, %47, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,256,14,14],f32>
      %150 = torch.aten.relu %149 : !torch.vtensor<[1,256,14,14],f32> -> !torch.vtensor<[1,256,14,14],f32>
      %151 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %152 = torch.aten.convolution %150, %44, %none, %101, %101, %101, %false, %151, %int1 : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[256,256,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,14,14],f32>
      %153 = torch.aten.batch_norm %152, %41, %40, %43, %42, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,256,14,14],f32>
      %154 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %155 = torch.aten.convolution %146, %39, %none, %99, %132, %101, %false, %154, %int1 : !torch.vtensor<[1,128,28,28],f32>, !torch.vtensor<[256,128,1,1],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,14,14],f32>
      %156 = torch.aten.batch_norm %155, %36, %40, %38, %37, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,256,14,14],f32>
      %157 = torch.aten.add.Tensor %153, %156, %int1 : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[1,256,14,14],f32>, !torch.int -> !torch.vtensor<[1,256,14,14],f32>
      %158 = torch.aten.relu %157 : !torch.vtensor<[1,256,14,14],f32> -> !torch.vtensor<[1,256,14,14],f32>
      %159 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %160 = torch.aten.convolution %158, %35, %none, %101, %101, %101, %false, %159, %int1 : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[256,256,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,14,14],f32>
      %161 = torch.aten.batch_norm %160, %32, %31, %34, %33, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,256,14,14],f32>
      %162 = torch.aten.relu %161 : !torch.vtensor<[1,256,14,14],f32> -> !torch.vtensor<[1,256,14,14],f32>
      %163 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %164 = torch.aten.convolution %162, %30, %none, %101, %101, %101, %false, %163, %int1 : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[256,256,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,256,14,14],f32>
      %165 = torch.aten.batch_norm %164, %27, %26, %29, %28, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.vtensor<[256],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,256,14,14],f32>
      %166 = torch.aten.add.Tensor %165, %158, %int1 : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[1,256,14,14],f32>, !torch.int -> !torch.vtensor<[1,256,14,14],f32>
      %167 = torch.aten.relu %166 : !torch.vtensor<[1,256,14,14],f32> -> !torch.vtensor<[1,256,14,14],f32>
      %168 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %169 = torch.aten.convolution %167, %25, %none, %99, %101, %101, %false, %168, %int1 : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[512,256,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,7,7],f32>
      %170 = torch.aten.batch_norm %169, %22, %21, %24, %23, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,512,7,7],f32>
      %171 = torch.aten.relu %170 : !torch.vtensor<[1,512,7,7],f32> -> !torch.vtensor<[1,512,7,7],f32>
      %172 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %173 = torch.aten.convolution %171, %20, %none, %101, %101, %101, %false, %172, %int1 : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[512,512,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,7,7],f32>
      %174 = torch.aten.batch_norm %173, %17, %16, %19, %18, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,512,7,7],f32>
      %175 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %176 = torch.aten.convolution %167, %15, %none, %99, %132, %101, %false, %175, %int1 : !torch.vtensor<[1,256,14,14],f32>, !torch.vtensor<[512,256,1,1],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,7,7],f32>
      %177 = torch.aten.batch_norm %176, %12, %16, %14, %13, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,512,7,7],f32>
      %178 = torch.aten.add.Tensor %174, %177, %int1 : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[1,512,7,7],f32>, !torch.int -> !torch.vtensor<[1,512,7,7],f32>
      %179 = torch.aten.relu %178 : !torch.vtensor<[1,512,7,7],f32> -> !torch.vtensor<[1,512,7,7],f32>
      %180 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %181 = torch.aten.convolution %179, %11, %none, %101, %101, %101, %false, %180, %int1 : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[512,512,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,7,7],f32>
      %182 = torch.aten.batch_norm %181, %8, %7, %10, %9, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,512,7,7],f32>
      %183 = torch.aten.relu %182 : !torch.vtensor<[1,512,7,7],f32> -> !torch.vtensor<[1,512,7,7],f32>
      %184 = torch.prim.ListConstruct  : () -> !torch.list<int>
      %185 = torch.aten.convolution %183, %6, %none, %101, %101, %101, %false, %184, %int1 : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[512,512,3,3],f32>, !torch.none, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.list<int>, !torch.int -> !torch.vtensor<[1,512,7,7],f32>
      %186 = torch.aten.batch_norm %185, %3, %2, %5, %4, %false, %float1.000000e-01, %float1.000000e-05, %true : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.vtensor<[512],f32>, !torch.bool, !torch.float, !torch.float, !torch.bool -> !torch.vtensor<[1,512,7,7],f32>
      %187 = torch.aten.add.Tensor %186, %179, %int1 : !torch.vtensor<[1,512,7,7],f32>, !torch.vtensor<[1,512,7,7],f32>, !torch.int -> !torch.vtensor<[1,512,7,7],f32>
      %188 = torch.aten.relu %187 : !torch.vtensor<[1,512,7,7],f32> -> !torch.vtensor<[1,512,7,7],f32>
      %189 = torch.prim.ListConstruct %int7, %int7 : (!torch.int, !torch.int) -> !torch.list<int>
      %190 = torch.prim.ListConstruct %int1, %int1 : (!torch.int, !torch.int) -> !torch.list<int>
      %191 = torch.prim.ListConstruct %int0, %int0 : (!torch.int, !torch.int) -> !torch.list<int>
      %192 = torch.aten.avg_pool2d %188, %189, %190, %191, %false, %true, %none : !torch.vtensor<[1,512,7,7],f32>, !torch.list<int>, !torch.list<int>, !torch.list<int>, !torch.bool, !torch.bool, !torch.none -> !torch.vtensor<[1,512,1,1],f32>
      %193 = torch.aten.flatten.using_ints %192, %int1, %int-1 : !torch.vtensor<[1,512,1,1],f32>, !torch.int, !torch.int -> !torch.vtensor<[1,512],f32>
      %194 = torch.aten.linear %193, %1, %0 : !torch.vtensor<[1,512],f32>, !torch.vtensor<[1000,512],f32>, !torch.vtensor<[1000],f32> -> !torch.vtensor<[1,1000],f32>
      return %194 : !torch.vtensor<[1,1000],f32>
    }
  }  